{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "* Create parameter dictionary\n",
    "* `blockTools` wrapper\n",
    "  * Transform raw output\n",
    "* Write cross-validation process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.datasets as datasets\n",
    "import sklearn.linear_model as linear_model\n",
    "\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_TYPE = 'binary'\n",
    "K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P = {'data': {'y_type': 'binary',\n",
    "              'n_units': 100,\n",
    "              'n_features': 20, 'n_informative': 2}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_synth_data(P):\n",
    "    '''Create a synthetic dataset using sample generators from scikit-learn. The target variable\n",
    "    is either binary, or continuous.'''\n",
    "    if P['data']['y_type'] == 'discrete':\n",
    "        X, y = datasets.make_classification(n_samples=P['data']['n_units'],\n",
    "                                            n_features=['data']['n_features'],\n",
    "                                            n_informative=['data']['n_informative'],\n",
    "                                            n_redundant=0, n_repeated=0, n_classes=['data']['n_classes'],\n",
    "                                            n_clusters_per_class=0, weights=['data']['weights'], flip_y=0.01,\n",
    "                                            class_sep=1.0, hypercube=False, shift=0.0, scale=1.0,\n",
    "                                            shuffle=True, random_state=None)\n",
    "    elif P['data']['y_type'] == 'continuous':\n",
    "        X, y = datasets.make_regression(n_samples=100, n_features=100, n_informative=10,\n",
    "                                        \n",
    "                                        n_targets=1, bias=0.0, effective_rank=None,\n",
    "                                        tail_strength=0.5, noise=0.0, shuffle=True, coef=False,\n",
    "                                        random_state=None)\n",
    "    return X, y\n",
    "\n",
    "def block(X):\n",
    "    '''Assign each unit to a block.'''\n",
    "    # Activate pandas conversion support\n",
    "    pandas2ri.activate()\n",
    "    # Import blockTools\n",
    "    block = importr('blockTools')\n",
    "    # Convert X to pandas DataFrame \n",
    "    df = pd.DataFrame(X, columns=['v{}'.format(i + 1) for i in xrange(X.shape[1])]).reset_index()\n",
    "    # Perform blocking\n",
    "    blocks = block.block(df, id_vars='index', block_vars='v1', n_tr=K)\n",
    "    # Extract assignment DataFrame\n",
    "    blocks = pandas2ri.ri2py_dataframe(blocks.rx2('blocks').rx2('1'))\n",
    "    # Remove column of max within-pair distance\n",
    "    max_dist = blocks.pop('Max Distance')\n",
    "    blocks.columns = np.arange(K)\n",
    "    blocks = blocks.T.stack()\n",
    "    blocks.index = blocks.index.droplevel(1)\n",
    "    blocks = blocks.reset_index()\n",
    "    blocks.columns = ['k', 'unit']\n",
    "    blocks['unit'] = blocks['unit'].astype(int)\n",
    "    return blocks, max_dist\n",
    "\n",
    "def fit_model():\n",
    "    model = linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0,\n",
    "                                            fit_intercept=True, intercept_scaling=1,\n",
    "                                            class_weight=None, random_state=None, solver='liblinear',\n",
    "                                            max_iter=100, multi_class='ovr', verbose=0,\n",
    "                                            warm_start=False, n_jobs=1)\n",
    "    for k in xrange(K):\n",
    "        is_test = np.array(folds.ix[folds['k'] == k, 'unit'])\n",
    "        model.fit(X[~is_test, ], y[~is_test])\n",
    "        print model.score(X[is_test, ], y[is_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create synthetic data\n",
    "X, y = simulate_data(Y_TYPE)\n",
    "\n",
    "# Use blockTools for cross-validation assignment\n",
    "folds, max_dist = block(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
