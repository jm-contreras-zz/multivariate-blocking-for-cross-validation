{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "* Finalize method to store cross-validation results and visualize accuracy and stability.\n",
    "* Visualize and report performance.\n",
    "* Perform due diligence on methods and check in with collaborator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import parameters as p\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.datasets as datasets\n",
    "import sklearn.linear_model as linear_model\n",
    "\n",
    "import rpy2.robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.packages import importr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_synth_data(p):\n",
    "    '''Create a synthetic dataset of variable size using sample generators from scikit-learn.\n",
    "    The number of informative features and the target variable type (discrete or continuous) are\n",
    "    also declareable parameters.\n",
    "    '''\n",
    "    if p.DISCRETE_Y:\n",
    "        X, y = datasets.make_classification(n_samples=p.N_SAMPLES, n_features=p.N_FEATURES,\n",
    "                                            n_informative=p.N_INFORMATIVE, n_redundant=0,\n",
    "                                            n_repeated=0, n_classes=p.N_CLASSES,\n",
    "                                            n_clusters_per_class=1, weights=p.WEIGHTS,\n",
    "                                            flip_y=0.01, class_sep=1.0, hypercube=False,\n",
    "                                            shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "    else:\n",
    "        X, y = datasets.make_regression(n_samples=p.N_SAMPLES, n_features=p.N_FEATURES,\n",
    "                                        n_informative=p.N_INFORMATIVE, n_targets=1, bias=0.0,\n",
    "                                        effective_rank=None, tail_strength=0.5, noise=0.0,\n",
    "                                        shuffle=True, coef=False, random_state=None)\n",
    "    \n",
    "    # Transform X from NumPy array to pandas DataFrame\n",
    "    X = pd.DataFrame(X, columns=['f{}'.format(i) for i in range(p.N_FEATURES)])\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def assign_folds(X, p):\n",
    "    '''Assign each unit in a dataset to a cross-validation fold using blockTools. The number of\n",
    "    folds as well as blockTools parameters are declarable.\n",
    "    '''\n",
    "    # Activate pandas conversion support\n",
    "    pandas2ri.activate()\n",
    "    # Import blockTools\n",
    "    blockTools = importr('blockTools')\n",
    "\n",
    "    # Name blocking features\n",
    "    block_vars = robjects.StrVector(X.columns)\n",
    "    # Assign units to blocks and then folds\n",
    "    blocks = blockTools.block(X.reset_index(), id_vars='index', block_vars=block_vars, n_tr=p.K)\n",
    "    folds = blockTools.assignment(blocks)\n",
    "    # Transform folds to DataFrame\n",
    "    folds = pandas2ri.ri2py_dataframe(folds.rx2('assg').rx2('1')).astype(int)\n",
    "\n",
    "    # Reformat DataFrame for cross-validation\n",
    "    max_dist = folds.pop('Max Distance')\n",
    "    folds.columns = np.arange(p.K)\n",
    "    folds = folds.stack()\n",
    "    folds.index = folds.index.droplevel(0)\n",
    "    folds = folds.reset_index()\n",
    "    folds.columns = ['k', 'unit']\n",
    "\n",
    "    return folds, max_dist\n",
    "\n",
    "def fit_model(X, y, folds, p):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create synthetic data\n",
    "X, y = make_synth_data(p)\n",
    "\n",
    "# Use blockTools for cross-validation assignment\n",
    "folds, max_dist = assign_folds(X, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.0"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0,\n",
    "                                        fit_intercept=True, intercept_scaling=1,\n",
    "                                        class_weight=None, random_state=None, solver='liblinear',\n",
    "                                        max_iter=100, multi_class='ovr', verbose=0,\n",
    "                                        warm_start=False, n_jobs=1)\n",
    "\n",
    "x = 0\n",
    "for k in range(p.K):\n",
    "    is_test = np.in1d(np.arange(p.N_SAMPLES), folds.ix[folds['k'] == k, 'unit'])\n",
    "    model.fit(X.ix[~is_test, :], y[~is_test])\n",
    "    x += model.score(X.ix[is_test, :], y[is_test])\n",
    "x * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folds['unit_shuffled'] = folds['unit'].sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.0"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0,\n",
    "                                        fit_intercept=True, intercept_scaling=1,\n",
    "                                        class_weight=None, random_state=None, solver='liblinear',\n",
    "                                        max_iter=100, multi_class='ovr', verbose=0,\n",
    "                                        warm_start=False, n_jobs=1)\n",
    "\n",
    "x = 0\n",
    "for k in range(p.K):\n",
    "    is_test = np.in1d(np.arange(p.N_SAMPLES), folds.ix[folds['k'] == k, 'unit_shuffled'])\n",
    "    model.fit(X.ix[~is_test, :], y[~is_test])\n",
    "    x += model.score(X.ix[is_test, :], y[is_test])\n",
    "x * 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
