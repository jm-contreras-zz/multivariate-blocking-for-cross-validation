{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "* Try this out with some real data.\n",
    "* Perform due diligence on methods and check in with collaborator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import parameters as p\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "\n",
    "import sklearn.datasets as datasets\n",
    "import sklearn.linear_model as linear_model\n",
    "\n",
    "import rpy2.robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_synth_data(p):\n",
    "    '''Create a synthetic dataset of variable size using sample generators from scikit-learn.\n",
    "    The number of informative features and the target variable type (discrete or continuous) are\n",
    "    also declareable parameters.\n",
    "    '''\n",
    "    if p.DISCRETE_Y:\n",
    "        X, y = datasets.make_classification(n_samples=p.N_SAMPLES, n_features=p.N_FEATURES,\n",
    "                                            n_informative=p.N_INFORMATIVE, n_redundant=0,\n",
    "                                            n_repeated=0, n_classes=p.N_CLASSES,\n",
    "                                            n_clusters_per_class=1, weights=p.WEIGHTS,\n",
    "                                            flip_y=0.01, class_sep=1.0, hypercube=False,\n",
    "                                            shift=0.0, scale=1.0, shuffle=True,\n",
    "                                            random_state=None)\n",
    "    else:\n",
    "        X, y = datasets.make_regression(n_samples=p.N_SAMPLES, n_features=p.N_FEATURES,\n",
    "                                        n_informative=p.N_INFORMATIVE, n_targets=1, bias=0.0,\n",
    "                                        effective_rank=None, tail_strength=0.5, noise=0.0,\n",
    "                                        shuffle=True, coef=False, random_state=None)\n",
    "    \n",
    "    # Transform X from NumPy array to pandas DataFrame\n",
    "    X = pd.DataFrame(X, columns=['f{}'.format(i) for i in range(p.N_FEATURES)])\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def assign_folds(X, p):\n",
    "    '''Assign each unit in a dataset to a cross-validation fold using blockTools. The number of\n",
    "    folds as well as blockTools parameters are declarable.\n",
    "    '''\n",
    "    # Activate pandas conversion support\n",
    "    pandas2ri.activate()\n",
    "    # Import blockTools\n",
    "    blockTools = importr('blockTools')\n",
    "\n",
    "    # Name blocking features\n",
    "    block_vars = rpy2.robjects.StrVector(X.columns)\n",
    "    # Assign units to blocks and then folds\n",
    "    blocks = blockTools.block(X.reset_index(), id_vars='index', block_vars=block_vars, n_tr=p.K)\n",
    "    folds = blockTools.assignment(blocks)\n",
    "    # Transform folds to DataFrame\n",
    "    folds = pandas2ri.ri2py_dataframe(folds.rx2('assg').rx2('1')).astype(int)\n",
    "\n",
    "    # Reformat DataFrame for cross-validation\n",
    "    max_dist = folds.pop('Max Distance')\n",
    "    folds.columns = np.arange(p.K)\n",
    "    folds = folds.stack()\n",
    "    folds.index = folds.index.droplevel(0)\n",
    "    folds = folds.reset_index()\n",
    "    folds.columns = ['k', 'unit']\n",
    "\n",
    "    return folds, max_dist\n",
    "\n",
    "def evaluate_model(model, X, y, folds, col, p):\n",
    "    '''Perform k-folds cross-validation using the column COL in FOLDS.'''\n",
    "    # Create DataFrame to hold results\n",
    "    df = pd.DataFrame(None, columns=['col', 'k', 'accuracy'])\n",
    "\n",
    "    # Iterate through folds\n",
    "    for k in range(p.K):\n",
    "        # Identify units in testing set\n",
    "        is_test = np.in1d(np.arange(p.N_SAMPLES), folds.ix[folds['k'] == k, col])\n",
    "        # Fit model on other units\n",
    "        model.fit(X.ix[~is_test, :], y[~is_test])\n",
    "        # Evaluate model accuracy on testing set\n",
    "        accuracy = model.score(X.ix[is_test, :], y[is_test])\n",
    "        df = df.append({'col': col, 'k': k, 'accuracy': accuracy}, ignore_index=True)\n",
    "    \n",
    "    # Return filled DataFrame\n",
    "    return df\n",
    "\n",
    "def visualize_results(data1, data2, x, y, x_lab, y_lab, x_tic):\n",
    "    '''Draw a violin plot to visualize the comparison between two value distributions.'''\n",
    "    sns.violinplot(x=x, y=y, data=data1.append(data2))\n",
    "    plt.title('{} by {}'.format(x_lab, y_lab), size=18, y=1.05)\n",
    "    plt.ylabel(y_lab, size=15)\n",
    "    plt.xlabel(x_lab, size=15)\n",
    "    plt.text(0.12, data1[y].median(), data1[y].median(), ha='center', va='center', fontsize=10)\n",
    "    plt.text(1.12, data2[y].median(), data2[y].median(), ha='center', va='center', fontsize=10)\n",
    "    plt.xticks(range(len(x_tic)), x_tic, size=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'parameters' from 'parameters.py'>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create synthetic data\n",
    "X, y = make_synth_data(p)\n",
    "\n",
    "# Use blockTools for cross-validation assignment\n",
    "folds, max_dist = assign_folds(X, p)\n",
    "\n",
    "# Shuffle cross-validation assignment as control\n",
    "folds['unit_shuffled'] = folds['unit'].sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0,\n",
    "                                        fit_intercept=True, intercept_scaling=1,\n",
    "                                        class_weight=None, random_state=None, solver='liblinear',\n",
    "                                        max_iter=100, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "treat = evaluate_model(model, X, y, folds, 'unit', p)\n",
    "control = evaluate_model(model, X, y, folds, 'unit_shuffled', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visualize_results(treat, control, 'col', 'accuracy',\n",
    "                  'Blocking Method', 'Classification Accuracy',\n",
    "                  ['blockTools', 'None'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
